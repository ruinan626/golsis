{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Codes for Team 2C\n",
    "### Lei Jin,Ruinan Lu, Yuanrui Li, Xianci Zhang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class DataStore:\n",
    "    def __init__(self, stdt, endt, freq = '300T', tickers=[\"XBTUSD\"]):\n",
    "        self.freq        = freq\n",
    "        self.startdate        = pd.to_datetime(stdt)\n",
    "        self.enddate        = pd.to_datetime(endt)\n",
    "        self.ticker_list= tickers\n",
    "    \n",
    "    def loadData(self, tag):\n",
    "        datelist=[x.strftime('%Y%m%d') for x in pd.date_range(start=self.startdate,end=self.enddate)]\n",
    "        li = []\n",
    "        for date in datelist:\n",
    "            path=path='https://s3-eu-west-1.amazonaws.com/public.bitmex.com/data/'+tag+'/'+date+'.csv.gz'\n",
    "            print (\"loading data\", tag, date)\n",
    "            df = pd.read_csv(path,compression='gzip',error_bad_lines=False)\n",
    "            df=df[df.symbol.isin(self.ticker_list)]\n",
    "            li.append(df)\n",
    "        frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "        frame[\"timestamp\"]=pd.to_datetime(frame[\"timestamp\"], errors='coerce',format='%Y-%m-%dD%H:%M:%S.%f')\n",
    "        return frame\n",
    "    \n",
    "    def loadTradeData(self):\n",
    "        if not hasattr(self, 'raw_tradeData'):\n",
    "            #trade=pd.read_csv(\"20190731M/trade.csv\")\n",
    "            #trade=trade.drop(columns=['Unnamed: 0'])\n",
    "            #trade[\"timestamp\"]=pd.to_datetime(trade[\"timestamp\"], \n",
    "                 #errors='coerce',format='%Y-%m-%d %H:%M:%S.%f')\n",
    "            #self.raw_tradeData = trade\n",
    "            self.raw_tradeData = self.loadData(\"trade\")\n",
    "        return self.raw_tradeData\n",
    "    \n",
    "    def loadQuoteData(self):\n",
    "        if not hasattr(self, 'raw_quoteData'):\n",
    "            #quote=pd.read_csv(\"20190731M/quote.csv\")            \n",
    "            #quote=quote.drop(columns=['Unnamed: 0'])\n",
    "            #quote[\"timestamp\"]=pd.to_datetime(quote[\"timestamp\"], \n",
    "                 #errors='coerce',format='%Y-%m-%d %H:%M:%S.%f')\n",
    "            #self.raw_quoteData = quote\n",
    "            self.raw_quoteData = self.loadData(\"quote\")\n",
    "        return self.raw_quoteData\n",
    "    \n",
    "    \n",
    "    def resampleQuote(self, df, frequency):\n",
    "        print (\"resampling quote data to \",frequency)\n",
    "        df=df.rename(columns={'bidSize':'bidSizeBalance','askSize':'askSizeBalance'})\n",
    "        df=df.sort_values('timestamp').groupby(['symbol']).resample(frequency,on=\"timestamp\").agg({'bidSizeBalance' : [\"min\",\"max\",\"last\"],\n",
    "                      'askSizeBalance' : [\"min\",\"max\",\"last\"],'bidPrice' : [\"min\",\"max\",\"last\"],'askPrice' : [\"min\",\"max\",\"last\"], 'timestamp':\"last\"}).reset_index()\n",
    "        df.columns = df.columns.map('_'.join)\n",
    "        df = df.reset_index().rename(columns={'symbol_':'symbol',\"timestamp_\":\"timestamp\",\"timestamp_last\":\"timestamp_lastQuote\"}).drop(columns=['index'])\n",
    "        df=df.dropna()\n",
    "        return df\n",
    "    \n",
    "    def resampleTrade(self, df, frequency):\n",
    "        print (\"resampling trade data to \",frequency)\n",
    "        df=df[[\"timestamp\",\"symbol\",\"side\",\"total_size\",\"price\"]].rename(columns={'total_size':'tradeSize','price':'tradePrice'})\n",
    "#        df=df.sort_values('timestamp').groupby(['symbol',\"side\"]).resample(frequency,on=\"timestamp\").agg({'tradeSize' : [\"min\",\"max\",\"last\",\"sum\"],\n",
    "#                      'tradePrice' : [\"min\",\"max\",\"last\",\"mean\"], 'timestamp':\"last\"}).reset_index()\n",
    "#        df.columns = df.columns.map('_'.join)\n",
    "#        df = df.reset_index().rename(columns={'symbol_':'symbol',\"timestamp_\":\"timestamp\",\"timestamp_last\":\"timestamp_lastTrade\"}).drop(columns=['index'])\n",
    "        \n",
    "        price_df=df.sort_values('timestamp').groupby(['symbol']).resample(\"15T\",on=\"timestamp\").agg({\n",
    "                      'tradePrice' : [\"min\",\"max\",\"last\",\"mean\"], 'timestamp':\"last\"}).reset_index()\n",
    "        price_df.columns = price_df.columns.map('_'.join)\n",
    "        price_df = price_df.reset_index().rename(columns={'symbol_':'symbol',\"timestamp_\":\"timestamp\",\"timestamp_last\":\"timestamp_lastTrade\"}).drop(columns=['index'])\n",
    "        \n",
    "        side_df=df.sort_values('timestamp').groupby(['symbol',\"side\"]).resample(\"15T\",on=\"timestamp\").agg({'tradeSize' : [\"min\",\"max\",\"last\",\"sum\"],\n",
    "                      'tradePrice' : [\"min\",\"max\",\"last\",\"mean\"], 'timestamp':[\"last\",\"count\"]}).reset_index()\n",
    "        side_df.columns = side_df.columns.map('_'.join)\n",
    "        side_df = side_df.reset_index().rename(columns={'symbol_':'symbol',\"timestamp_\":\"timestamp\",\"side_\":\"side\",\"timestamp_last\":\"timestamp_lastTrade\"}).drop(columns=['index'])\n",
    "        total_size = pd.pivot_table(side_df, values='tradeSize_sum', index=[\"symbol\",\"timestamp\"], columns=['side'])\n",
    "        total_size=total_size.reset_index().rename(columns={'Buy':'Buy_totalSize',\"Sell\":\"Sell_totalSize\"})\n",
    "        df=price_df.merge(total_size, on=['symbol','timestamp'], how='left')\n",
    "        df=df.dropna()\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def aggregateTrade(self, df):\n",
    "        df=df.groupby(['timestamp', 'symbol', 'side', 'price']).agg({'size':{'total_size': 'sum'}})\n",
    "        df.columns = df.columns.droplevel(0)\n",
    "        df=df.reset_index()\n",
    "        return df\n",
    " \n",
    "    def resampleData(self):\n",
    "        if not hasattr(self, 'resampledData'):\n",
    "            quote=self.loadQuoteData()\n",
    "            trade=self.loadTradeData()\n",
    "            \n",
    "            \n",
    "            trade=self.aggregateTrade(trade)\n",
    "            quote=self.resampleQuote(quote,self.freq)\n",
    "            trade=self.resampleTrade(trade,self.freq)\n",
    "            self.resampledData = pd.merge(quote,trade, on=[\"symbol\", \"timestamp\"], how=\"left\")\n",
    "#            self.resampledData = self.resampledData.dropna()\n",
    "        return self.resampledData\n",
    "            \n",
    "#        for frequency in self.freq:\n",
    "#            if frequency not in (self.resampledData.keys()):\n",
    "#                quote.to_csv(\"quote.csv\")\n",
    "#                trade.to_csv(\"trade.csv\")\n",
    "#                quote=pd.read_csv(\"quote.csv\")\n",
    "#                trade=pd.read_csv(\"trade.csv\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_interval_distribution(datastore):\n",
    "    raw_tradeData=datastore.raw_tradeData\n",
    "    trade_intervals=raw_tradeData.groupby(['symbol','side'])[\"timestamp\"].diff().dt.seconds\n",
    "    trade_intervals=trade_intervals[(trade_intervals<100)&(trade_intervals>1)]\n",
    "    trade_intervals.hist(bins=100)\n",
    "    plt.title(\"distribution of interval between orders\")\n",
    "    plt.xlabel(\"seconds\")\n",
    "    plt.ylabel(\"counts\")\n",
    "    plt.show()\n",
    "    raw_quoteData=datastore.raw_quoteData\n",
    "    trade_intervals=raw_quoteData.groupby(['symbol'])[\"timestamp\"].diff().dt.seconds\n",
    "    trade_intervals=trade_intervals[(trade_intervals<60)&(trade_intervals>1)]\n",
    "    trade_intervals.hist(bins=100)\n",
    "    plt.title(\"distribution of interval between trades\")\n",
    "    plt.xlabel(\"seconds\")\n",
    "    plt.ylabel(\"counts\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factor Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def test_factor(df, x_name,y_name):\n",
    "    df=df.dropna()\n",
    "    model=sm.OLS(df[y_name],sm.add_constant(df[x_name])).fit()\n",
    "    print (model.summary())\n",
    "#    df.plot.scatter(x=x_name,y=y_name)\n",
    "#    plt.show()\n",
    "    for x in x_name:\n",
    "        sub_model=sm.OLS(df[y_name],sm.add_constant(df[x])).fit()\n",
    "        print (sub_model.summary())\n",
    "\n",
    "\n",
    "def plot_corr_heatmap(X, title=\"Corr Heatmap\"):\n",
    "    X_corr = X.corr()\n",
    "    plt.figure(figsize=(16,10))\n",
    "    plt.title(title)\n",
    "    mask = np.zeros_like(X_corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "    sns.heatmap(mask=mask, data=X_corr, annot=True, cmap=cmap)\n",
    "\n",
    "def pairplot_with_target(X,frequency ,features, target):\n",
    "    def pairplot(x, y, **kwargs):\n",
    "        ax = plt.gca()\n",
    "        ts = pd.DataFrame({'x': x, 'y': y})\n",
    "        ts=ts.dropna()\n",
    "        ts.plot.scatter(x=\"x\",y=\"y\",ax=ax)\n",
    "        plt.xticks(rotation=90)\n",
    "    f = pd.melt(X, id_vars=[target], value_vars=features)\n",
    "    g = sns.FacetGrid(f, col=\"variable\",  col_wrap=3, sharex=False, sharey=False, size=3)\n",
    "    g = g.map(pairplot, \"value\", target)\n",
    "    g.fig.subplots_adjust(top=0.9)\n",
    "    g.fig.suptitle(\"scatter plot feature vs. return, interval=\"+frequency+\" minutes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factor Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#make features\n",
    "def feature_engineer(df, features=['lob_sizeImbalance','midPrice','midPrice_return','bidAskSpread','normalized_bidAskSpread','tradePriceMomentum','tradePriceVolatility','trade_sizeImbalance']):\n",
    "    print (df.columns)\n",
    "    df[\"lob_sizeImbalance\"]=(df[\"bidSizeBalance_last\"]-df[\"askSizeBalance_last\"])/(df[\"bidSizeBalance_last\"]+df[\"askSizeBalance_last\"])\n",
    "    df[\"midPrice\"]=(df[\"bidPrice_last\"]+df[\"askPrice_last\"])/2\n",
    "    df['midPrice_return'] = df.sort_values('timestamp').groupby(['symbol'])[\"midPrice\"].pct_change(1)\n",
    "    df[\"bidAskSpread\"]=(df[\"bidPrice_last\"]-df[\"askPrice_last\"])\n",
    "    df[\"normalized_bidAskSpread\"]=(df[\"bidPrice_last\"]-df[\"askPrice_last\"])/(df[\"tradePrice_last\"])\n",
    "    df['return'] = df.sort_values('timestamp').groupby(['symbol'])[\"tradePrice_last\"].pct_change(1)\n",
    "    df['tradePriceMomentum'] = (df[\"tradePrice_last\"]-df[\"tradePrice_min\"])/(df[\"tradePrice_max\"]-df[\"tradePrice_min\"])\n",
    "    df['tradePriceVolatility'] = np.log(df[\"tradePrice_max\"])-np.log(df[\"tradePrice_min\"])\n",
    "    df[\"trade_sizeImbalance\"]=(df[\"Buy_totalSize\"]-df[\"Sell_totalSize\"])/(df[\"Buy_totalSize\"]+df[\"Sell_totalSize\"]) \n",
    "    df=df.set_index('timestamp')\n",
    "    df['next_return']=df['return'].shift(-1)\n",
    "    df=df.iloc[:-1,:]\n",
    "    df = df.dropna()\n",
    "    return df[features], df['tradePrice_last'], df['next_return']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn import model_selection\n",
    "#from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import Imputer\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "     \n",
    "class Engine:\n",
    "    \n",
    "    def __init__(self, data, price, next_return):\n",
    "        self.raw_data = data\n",
    "        self.price = price\n",
    "        self.next_return = next_return\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.X_valid = None\n",
    "        self.y_valid = None\n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "        self.performance_history=None\n",
    "        \n",
    "        self.preprocess_params = {\"imputer\": None,\n",
    "                                  \"normalizer\": None,\n",
    "                                  \"boxcox_X_lam\": {},\n",
    "                                  \"boxcox_y_lam\": None}\n",
    "        self.model = {\"OLS\": None,\n",
    "                     \"logisticR\": None}\n",
    "        \n",
    "    def train_test_split(self, base_features, target='next_return'):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = model_selection.train_test_split(self.raw_data[base_features], self.next_return, random_state = 0)\n",
    "        self.X_train=self.X_train.sort_index()\n",
    "        self.X_test=self.X_test.sort_index()\n",
    "        self.y_train=self.y_train.sort_index()\n",
    "        self.y_test=self.y_test.sort_index()\n",
    "        \n",
    "    # preprocessing:\n",
    "    def __impute(self, X, train=False, strategy='constant'):\n",
    "        ind = X.index\n",
    "        col = X.columns\n",
    "        if train:\n",
    "            #using constant imputer for price volatility and standard scaler for normalization\n",
    "            self.preprocess_params[\"imputer\"] = Imputer(strategy=strategy)\n",
    "            X = pd.DataFrame(self.preprocess_params[\"imputer\"].fit_transform(X), columns=col, index=ind)\n",
    "        else:\n",
    "            X = pd.DataFrame(self.preprocess_params[\"imputer\"].transform(X), columns=col, index=ind)\n",
    "        return X\n",
    "    \n",
    "    def __boxcox(self, X, is_X=True, train=False):\n",
    "        '''is_X: True, boxcox for X; False, boxcox for y\n",
    "        '''\n",
    "        ind = X.index\n",
    "        res = pd.DataFrame(index=ind)\n",
    "        for col_name, series in X.iteritems():\n",
    "            if train:\n",
    "                bc = boxcox(series)\n",
    "                res[col_name] = bc[0]\n",
    "                if is_X:\n",
    "                    self.preprocess_params[\"boxcox_X_lam\"][col_name] = bc[1]\n",
    "                else:\n",
    "                    self.preprocess_params[\"boxcox_y_lam\"] = bc[1]\n",
    "            else:\n",
    "                if is_X:\n",
    "                    lam = self.preprocess_params[\"boxcox_X_lam\"][col_name]\n",
    "                else:\n",
    "                    lam = self.preprocess_params[\"boxcox_y_lam\"]\n",
    "                res[col_name] = boxcox(series, lmbda=lam)\n",
    "        return res\n",
    "    \n",
    "    def __boxcox_inv(self, y, lmbda):\n",
    "        '''inverse boxcox transformation\n",
    "        '''\n",
    "        if lmbda == 0:\n",
    "            return np.exp(y)\n",
    "        else:\n",
    "            return np.power(lmbda * y + 1, 1 / lmbda)\n",
    "    \n",
    "    def boxcox_inv(self, y, lmbda):\n",
    "        return self.__boxcox_inv(y, lmbda)\n",
    "    \n",
    "    def __normalize(self, X, train=False):\n",
    "        ind = X.index\n",
    "        col = X.columns\n",
    "        if train:\n",
    "            #normalizer\n",
    "            self.preprocess_params[\"normalizer\"] = StandardScaler()\n",
    "            X = pd.DataFrame(self.preprocess_params[\"normalizer\"].fit_transform(X), columns=col, index=ind)\n",
    "        else:\n",
    "            X = pd.DataFrame(self.preprocess_params[\"normalizer\"].transform(X), columns=col, index=ind)\n",
    "        return X\n",
    "    \n",
    "    def preprocessing(self, impute=True, boxcox=True, normalize=True, **kwargs):\n",
    "        '''other parameters: strategy\n",
    "        '''\n",
    "        if impute:\n",
    "            self.X_train = self.__impute(self.X_train, train=True, strategy=kwargs['strategy'])\n",
    "            self.X_test = self.__impute(self.X_test, train=False, strategy=kwargs['strategy'])\n",
    "        \n",
    "        if boxcox:\n",
    "            self.X_train = self.__boxcox(1 + self.X_train, is_X=True, train=True)\n",
    "            self.y_train = self.__boxcox(1 + self.y_train, is_X=False, train=True)\n",
    "            self.X_test = self.__boxcox(1 + self.X_test, is_X=True, train=False)\n",
    "            self.y_test = self.__boxcox(1 + self.y_test, is_X=False, train=False)\n",
    "        \n",
    "        if normalize:\n",
    "            self.X_train = self.__normalize(self.X_train, train=True)\n",
    "            self.X_test = self.__normalize(self.X_test, train=False)\n",
    "    \n",
    "    # model\n",
    "    def build_ols(self,summary_tag=True):\n",
    "        '''simple neural network\n",
    "        '''\n",
    "        self.model[\"OLS\"] = sm.OLS(self.y_train,sm.add_constant(self.X_train), missing='drop').fit()\n",
    "        if summary_tag:\n",
    "            print (self.model[\"OLS\"].summary())\n",
    "          \n",
    "    def build_lgr(self,summary_tag=True):\n",
    "        '''simple neural network\n",
    "        '''\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        self.model[\"logisticR\"] = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(sm.add_constant(self.X_train), (self.y_train > 0.0).astype(int))\n",
    "#        if summary_tag:\n",
    "#            print (self.model[\"logisticR\"].summary())\n",
    "\n",
    "    # train:\n",
    "    def train(self, model):\n",
    "        \"\"\"model: OLS, LGR\n",
    "        \"\"\"\n",
    "        if model=='OLS': self.build_ols(summary_tag=True)\n",
    "        if model=='logisticR': self.build_lgr(summary_tag=True)\n",
    "\n",
    "    # predict\n",
    "    def predict(self, model, X):\n",
    "        y_pred = self.model[model].predict(sm.add_constant(X))\n",
    "        if self.preprocess_params[\"boxcox_y_lam\"]:\n",
    "            y_pred = self.__boxcox_inv(y_pred, self.preprocess_params[\"boxcox_y_lam\"]) - 1\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    def _plot_prediction(prediction, actual, index):\n",
    "        pyplot.plot(actual, label='actual', color='red')\n",
    "        pyplot.plot(prediction, label='prediction', color='blue')\n",
    "        pyplot.title(\"actual vs. prediction\")\n",
    "        pyplot.legend()\n",
    "        pyplot.show()\n",
    "        \n",
    "    \n",
    "    # evaluate:\n",
    "    def score(self, predict, true):\n",
    "        return mean_absolute_error(predict, true), np.sqrt(mean_squared_error(predict, true))\n",
    "    \n",
    "    def result_evaluation(self, predict, true):\n",
    "        self.plot_predictions(predict, true)\n",
    "        mae,mse=self.score(predict, true)\n",
    "        print (\"MAE:\",mae,\"MSE\",mse)\n",
    "        \n",
    "    \n",
    "    def plot_predictions(self, predict, true):\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.title('testing set: actual vs. prediction')\n",
    "        predict.plot(label='predicted price')\n",
    "        true.plot(label='actual price')\n",
    "        plt.xlabel('date')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Backtest:\n",
    "    \n",
    "    def __init__(self, engine):  # trained engine\n",
    "        self.price = engine.price\n",
    "        self.next_return = engine.next_return\n",
    "        self.train_period = engine.y_train.index\n",
    "        self.test_period = engine.y_test.index\n",
    "        \n",
    "        self.y_train_pred = np.mean([engine.predict(\"OLS\", engine.X_train)], axis=0)\n",
    "        self.y_test_pred = np.mean([engine.predict(\"OLS\", engine.X_test)], axis=0)\n",
    "\n",
    "    \n",
    "    def init_trade(self, which):\n",
    "        '''initialize trade\n",
    "        '''\n",
    "        assert which in ['train', 'valid', 'test']\n",
    "        \n",
    "        # Account\n",
    "        self.cash = self.init_cap = 1.0e8\n",
    "        self.position = {}\n",
    "        \n",
    "        # trade date, open/close signal\n",
    "        if which == 'train':\n",
    "            self._trade_date = self.train_period\n",
    "            self._y_pred = self.y_train_pred\n",
    "        elif which == 'valid':\n",
    "            self._trade_date = self.valid_period\n",
    "            self._y_pred = self.y_valid_pred\n",
    "        else:\n",
    "            self._trade_date = self.test_period\n",
    "            self._y_pred = self.y_test_pred\n",
    "        \n",
    "        self._price_list = self.price.loc[self._trade_date].values\n",
    "        self._return_list = self.next_return.loc[self._trade_date].values\n",
    "        \n",
    "        self._get_signal()\n",
    "        \n",
    "        self.__trade_date_iter = iter(self._trade_date)\n",
    "        self.__price_list_iter = iter(self._price_list)\n",
    "        self.__return_list_iter = iter(self._return_list)\n",
    "        \n",
    "        self.__open_date = next(self._open_signal_iter)\n",
    "        self.__close_date = next(self._close_signal_iter)\n",
    "        \n",
    "        # risk\n",
    "        self.tdays = len(self._trade_date)\n",
    "        self.total_returns = []\n",
    "        self.risk_indicators_dict = {}\n",
    "    \n",
    "    def _get_signal(self):\n",
    "        '''open and close signal\n",
    "        '''\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def __update_position_info(self, price):\n",
    "        '''update position infomation daily\n",
    "        '''\n",
    "        if self.position:\n",
    "            self.position['Bitcoin']['price'] = price\n",
    "            self.position['Bitcoin']['cap'] = self.position['Bitcoin']['price'] * self.position['Bitcoin']['number']\n",
    "            self.position['Bitcoin']['holding days'] += 1\n",
    "    \n",
    "    def __open(self, price):\n",
    "        num = self.cash / price\n",
    "        self.position['Bitcoin'] = {'price': price, 'number': num, 'cap': self.cash, 'holding days': 0}\n",
    "        self.cash = 0\n",
    "        \n",
    "    def __close(self):\n",
    "        self.cash = self.position['Bitcoin']['cap']\n",
    "        self.position.pop('Bitcoin')\n",
    "        \n",
    "        \n",
    "    # Risks\n",
    "    def __cal_total_returns(self):\n",
    "        self.total_cap = self.position['Bitcoin']['cap'] if self.position else self.cash\n",
    "        self.total_returns.append(np.log(self.total_cap) - np.log(self.init_cap))\n",
    "        \n",
    "    def __cal_total_annualized_returns(self):\n",
    "        self.total_annualized_returns = self.total_returns[-1] * 250.0 / self.tdays\n",
    "        self.risk_indicators_dict['Annualized Return'] = self.total_annualized_returns\n",
    "    \n",
    "    def __cal_daily_returns(self):\n",
    "        self.daily_returns = np.array(self.total_returns)[1:] - np.array(self.total_returns)[:-1]\n",
    "    \n",
    "    def __cal_annualized_volatility(self):\n",
    "        self.annualized_volatility = self.daily_returns.std() * np.sqrt(250)\n",
    "        self.risk_indicators_dict['Annualized Volatility'] = self.annualized_volatility\n",
    "\n",
    "    def __cal_sharpe(self):\n",
    "        self.sharpe = self.total_annualized_returns / self.annualized_volatility\n",
    "        self.risk_indicators_dict['Sharpe Ratio'] = self.sharpe\n",
    "        \n",
    "    def __cal_max_drawdown(self):\n",
    "        caps = self.init_cap * np.exp(self.total_returns)\n",
    "        start = end = 0\n",
    "        i = 0\n",
    "        mdd = 0\n",
    "        cap_max = caps[0]\n",
    "        for k, cap in enumerate(caps):\n",
    "            if k > i and 1 - cap / cap_max > mdd:\n",
    "                mdd = 1 - cap / cap_max\n",
    "                end = k\n",
    "                start = i\n",
    "            if cap > cap_max:\n",
    "                cap_max = cap\n",
    "                i = k\n",
    "        if mdd == 0:\n",
    "            self.max_drawdown = 0\n",
    "            self.mdd_start = None\n",
    "            self.mdd_end = None\n",
    "        else:\n",
    "            self.max_drawdown = mdd\n",
    "            self.mdd_start = self._trade_date[start]\n",
    "            self.mdd_end = self._trade_date[end]\n",
    "        self.risk_indicators_dict['Max DrawDown'] = self.max_drawdown\n",
    "    \n",
    "    def __do_daily_calculation(self):\n",
    "        self.__cal_total_returns()\n",
    "        \n",
    "    def get_risk_indicators(self):\n",
    "        self.__cal_daily_returns()\n",
    "        self.__cal_total_annualized_returns()\n",
    "        self.__cal_annualized_volatility()\n",
    "        self.__cal_sharpe()\n",
    "        self.__cal_max_drawdown()\n",
    "\n",
    "    def visualize_PNL(self, size=(6, 4), linewidth=('2', '3'), color=('r', 'black')):\n",
    "        total_returns = pd.Series(self.total_returns, index=self._trade_date)\n",
    "        fig = plt.figure(figsize=size)\n",
    "        ax1 = fig.add_subplot(111)\n",
    "        ax1.plot(total_returns, linewidth=linewidth[0], color=color[0])\n",
    "        plt.axhline(0, linewidth=linewidth[1], color=color[1])\n",
    "        plt.title(\"cumulative return\")\n",
    "        ax1.set_xlim(left=self._trade_date[0])\n",
    "        ax1.plot()\n",
    "        ax1.yaxis.grid(True)\n",
    "\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        date = next(self.__trade_date_iter)\n",
    "        price = next(self.__price_list_iter)\n",
    "\n",
    "        self.__update_position_info(price)\n",
    "        \n",
    "        self.__do_daily_calculation()\n",
    "        \n",
    "        if date == self.__close_date:\n",
    "            # close position\n",
    "            self.__close()\n",
    "            self.__close_date = next(self._close_signal_iter)\n",
    "        \n",
    "        if date == self.__open_date:\n",
    "            # open position\n",
    "            self.__open(price)\n",
    "            self.__open_date = next(self._open_signal_iter)\n",
    "        return\n",
    "    \n",
    "    def Run(self):\n",
    "        for _ in self:\n",
    "            pass\n",
    "        self.get_risk_indicators()\n",
    "\n",
    "class Strategy_A(Backtest):\n",
    "    \n",
    "    def __init__(self, engine):\n",
    "        Backtest.__init__(self, engine)\n",
    "    \n",
    "    def _get_signal(self):\n",
    "        y_pred = self._y_pred\n",
    "        \n",
    "        holding_days = self._y_pred.shape[0]\n",
    "        true_return = self._return_list\n",
    "        print (\"holding_days: \", holding_days)\n",
    "        open_signal = pd.Series(y_pred > true_return)\n",
    "        is_holding = open_signal.rolling(window=holding_days-1, min_periods=1).apply(lambda x: x.any()).shift(1).fillna(0.0).astype(\"bool\")\n",
    "        open_signal &= ~is_holding\n",
    "        close_signal = open_signal.shift(holding_days).fillna(False)\n",
    "        open_signal = self._trade_date[open_signal.values]\n",
    "        close_signal = self._trade_date[close_signal.values]\n",
    "        \n",
    "        # append a date so that open_signal and close_signal iterators will not end before trade_date iterator\n",
    "        self._open_signal_iter = iter(np.append(open_signal, np.datetime64('2020-01-01')))\n",
    "        self._close_signal_iter = iter(np.append(close_signal, np.datetime64('2020-01-01')))\n",
    "        \n",
    "class Strategy_B(Backtest):\n",
    "    \n",
    "    def __init__(self, engine):\n",
    "        Backtest.__init__(self, engine)\n",
    "    \n",
    "    def _get_signal(self):\n",
    "        y_pred = self._y_pred\n",
    "        \n",
    "        holding_days = self._y_pred.shape[0]\n",
    "#        true_return = self._return_list\n",
    "        print (\"holding_days: \", holding_days)\n",
    "        open_signal = pd.Series(y_pred > 0)\n",
    "        is_holding = open_signal.rolling(window=holding_days-1, min_periods=1).apply(lambda x: x.any()).shift(1).fillna(0.0).astype(\"bool\")\n",
    "        open_signal &= ~is_holding\n",
    "        close_signal = open_signal.shift(holding_days).fillna(False)\n",
    "        open_signal = self._trade_date[open_signal.values]\n",
    "        close_signal = self._trade_date[close_signal.values]\n",
    "        \n",
    "        # append a date so that open_signal and close_signal iterators will not end before trade_date iterator\n",
    "        self._open_signal_iter = iter(np.append(open_signal, np.datetime64('2020-01-01')))\n",
    "        self._close_signal_iter = iter(np.append(close_signal, np.datetime64('2020-01-01')))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataDownloader as db\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.expand_frame_repr', False)    \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import EDA as eda\n",
    "import factorEvaluate as factorEvaluator\n",
    "import factorGenerate as factorGenerator\n",
    "import predictionModel as model\n",
    "import strategy as backtest\n",
    "\n",
    "#%%\n",
    "\n",
    "#config\n",
    "start_date='20160801'\n",
    "end_date='20160801'\n",
    "frequency=\"15T\"#how many minutes:300T=5h\n",
    "#load data\n",
    "datastore = db.DataStore(start_date,end_date,frequency)\n",
    "data=datastore.resampleData()\n",
    "eda.plot_interval_distribution(datastore)\n",
    "#%%\n",
    "#factor engineer\n",
    "data, price, target_return = factorGenerator.feature_engineer(data)\n",
    "base_features = list(set(data.columns))\n",
    "data_df=pd.concat([data, target_return], axis=1)\n",
    "#%%\n",
    "factorEvaluator.test_factor(data_df, base_features,'next_return')\n",
    "factorEvaluator.plot_corr_heatmap(data_df.corr(),title=\"Corr Heatmap for interval=\"+frequency+\" minutes\")\n",
    "factorEvaluator.pairplot_with_target(data_df,frequency, list(set(data.columns) - set(['symbol'])), 'next_return')\n",
    "\n",
    "#%%\n",
    "##################### \n",
    "#set up model\n",
    "engine = model.Engine(data, price, target_return)\n",
    "engine.train_test_split(base_features)\n",
    "engine.preprocessing(boxcox=False, strategy='constant')\n",
    "#prediction\n",
    "engine.train('OLS')\n",
    "test_predict=engine.predict('OLS', engine.X_test)\n",
    "engine.result_evaluation(test_predict,engine.y_test)\n",
    "#%%\n",
    "########################\n",
    "#back testing\n",
    "strategy_A = backtest.Strategy_A(engine)\n",
    "strategy_A.init_trade('test')\n",
    "strategy_A.Run()\n",
    "strategy_A.visualize_PNL()\n",
    "print (strategy_A.risk_indicators_dict)\n",
    "\n",
    "#%%\n",
    "########################\n",
    "#back testing\n",
    "strategy_B = backtest.Strategy_B(engine)\n",
    "strategy_B.init_trade('test')\n",
    "strategy_B.Run()\n",
    "strategy_B.visualize_PNL()\n",
    "print (strategy_A.risk_indicators_dict)\n",
    "\n",
    "\n",
    "#%%\n",
    "##################### \n",
    "#direction model\n",
    "engine.train('logisticR')\n",
    "test_predict=pd.DataFrame(engine.predict('logisticR', engine.X_test), index=engine.X_test.index)\n",
    "engine.result_evaluation(test_predict,(engine.y_test > 0.0).astype(int))\n",
    "########################\n",
    "#back testing\n",
    "strategy_B = backtest.Strategy_B(engine)\n",
    "strategy_B.init_trade('test')\n",
    "strategy_B.Run()\n",
    "strategy_B.visualize_PNL()\n",
    "print (strategy_A.risk_indicators_dict)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
